{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26d5d6c8",
   "metadata": {},
   "source": [
    "Web scraping jobs on linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b040c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Working directory\n",
    "parent_dir = r'C:\\Users\\garcia38\\Dropbox\\Projects\\project_linkedin\\web-scraping-linkedin'\n",
    "os.chdir(parent_dir)\n",
    "\n",
    "## Create a folder where to store the code and save this notebook there\n",
    "if not os.path.isdir('code'):\n",
    "    os.mkdir('code')\n",
    "\n",
    "## Create a folder where to store the raw data\n",
    "if not os.path.isdir('data-raw'):\n",
    "    os.mkdir('data-raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b15f660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv \n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13cb4f8f",
   "metadata": {},
   "source": [
    "Define function to web scrape jobs on Linkedin and write them into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f01673",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def webscraper_linkedin(webpage_base, page_number, max_page_number):\n",
    "    \n",
    "    ## Define URL\n",
    "    webpage = webpage_base + str(page_number)\n",
    "    print(str(webpage)) \n",
    "\n",
    "    ## Send HTTP request to retrieve the HTML code and store it \n",
    "    response = requests.get(str(webpage)) \n",
    "    \n",
    "    ## Parse the HTML code\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "    print(response)\n",
    "\n",
    "    ## Access the data needed (all job listings are wrapped in a <div> with the following class)\n",
    "    jobs = soup.find_all('div', class_='base-card relative w-full hover:no-underline focus:no-underline base-card--link base-search-card base-search-card--link job-search-card')\n",
    "\n",
    "    ## Loop over the CSS selectors\n",
    "    for job in jobs:\n",
    "        job_title = job.find('h3', class_='base-search-card__title').text.strip()\n",
    "        job_company = job.find('h4', class_='base-search-card__subtitle').text.strip()\n",
    "        job_location = job.find('span', class_='job-search-card__location').text.strip()\n",
    "        job_date = job.find('time', class_='job-search-card__listdate')\n",
    "        pattern = re.compile('([0-9]{4})-([0-9]{2})-([0-9]{2})')\n",
    "        if pattern.findall(str(job_date)):\n",
    "            job_datem = pattern.search(str(job_date))[0]\n",
    "        else:\n",
    "            job_datem = 'None'\n",
    "        job_link = job.find('a', class_='base-card__full-link')['href']\n",
    "        \n",
    "        # Write extracted data into csv file\n",
    "        writer.writerow([job_title, job_company, job_location, job_datem, job_link])\n",
    "    \n",
    "    if page_number < max_page_number:\n",
    "        page_number = page_number + 25 # increase the start parameter by 25\n",
    "        webscraper_linkedin(webpage_base, page_number, max_page_number)\n",
    "    else:\n",
    "        file.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21374c17",
   "metadata": {},
   "source": [
    "Web scraping Data Analyst jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22829355",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove file if exists\n",
    "import os\n",
    "\n",
    "filename = os.path.join(parent_dir, 'data-raw', 'linkedin_jobs_dataanalyst.csv')\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c3779b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data+Analyst&location=Innere+Stadt,+Vienna,+Austria&geoId=104916553&f_TPR=r2592000&f_PP=105890822,104916553&distance=50&f_JT=F,P,C&f_E=3,2,4&currentJobId=3452827396&position=10&pageNum=1&start=0\n",
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "## Open csv file and write headers\n",
    "file = open(os.path.join(parent_dir, 'data-raw', 'linkedin_jobs_dataanalyst.csv'), 'a', newline='', encoding=\"utf-8-sig\")\n",
    "writer = csv.writer(file)\n",
    "headers = ['Title', 'Company', 'Location', 'Date', 'Link']\n",
    "writer.writerow(headers)\n",
    "\n",
    "## Define URL\n",
    "url_linkedin = 'https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search?keywords=Data+Analyst&location=Innere+Stadt,+Vienna,+Austria&geoId=104916553&f_TPR=r2592000&f_PP=105890822,104916553&distance=50&f_JT=F,P,C&f_E=3,2,4&currentJobId=3452827396&position=10&pageNum=1&start='\n",
    "\n",
    "## Run function\n",
    "webscraper_linkedin(url_linkedin, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b315664c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the csv file\n",
    "import pandas as pd\n",
    "\n",
    "dataanalyst = pd.read_csv(os.path.join(parent_dir, 'data-raw', 'linkedin_jobs_dataanalyst.csv'), encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44ae9da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst (f/m/x)</td>\n",
       "      <td>Mondi Group</td>\n",
       "      <td>Vienna, Vienna, Austria</td>\n",
       "      <td>2023-02-07</td>\n",
       "      <td>https://at.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Project and Data Analyst (m/f/d)</td>\n",
       "      <td>Netconomy</td>\n",
       "      <td>Vienna, Vienna, Austria</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>https://at.linkedin.com/jobs/view/project-and-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cloud Data Analyst (m/f/d)</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>Vienna, Vienna, Austria</td>\n",
       "      <td>2023-02-09</td>\n",
       "      <td>https://at.linkedin.com/jobs/view/cloud-data-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cloud Data Analyst (m/f/d)</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>Vienna, Vienna, Austria</td>\n",
       "      <td>2023-02-09</td>\n",
       "      <td>https://at.linkedin.com/jobs/view/cloud-data-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cloud Data Analyst (m/f/d)</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>Vienna, Vienna, Austria</td>\n",
       "      <td>2023-02-06</td>\n",
       "      <td>https://at.linkedin.com/jobs/view/cloud-data-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Title      Company                 Location  \\\n",
       "0              Data Analyst (f/m/x)  Mondi Group  Vienna, Vienna, Austria   \n",
       "1  Project and Data Analyst (m/f/d)    Netconomy  Vienna, Vienna, Austria   \n",
       "2        Cloud Data Analyst (m/f/d)      Siemens  Vienna, Vienna, Austria   \n",
       "3        Cloud Data Analyst (m/f/d)      Siemens  Vienna, Vienna, Austria   \n",
       "4        Cloud Data Analyst (m/f/d)      Siemens  Vienna, Vienna, Austria   \n",
       "\n",
       "         Date                                               Link  \n",
       "0  2023-02-07  https://at.linkedin.com/jobs/view/data-analyst...  \n",
       "1  2023-01-31  https://at.linkedin.com/jobs/view/project-and-...  \n",
       "2  2023-02-09  https://at.linkedin.com/jobs/view/cloud-data-a...  \n",
       "3  2023-02-09  https://at.linkedin.com/jobs/view/cloud-data-a...  \n",
       "4  2023-02-06  https://at.linkedin.com/jobs/view/cloud-data-a...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Inspect the data\n",
    "dataanalyst.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa2450c9d3e5eb4aaee00e8ddf13aa9e58897289195054c7456341d3a2406a02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
